server:
  port: 8080
  servlet:
    context-path: /api
spring:
  profiles:
    active: dev
  boot:
    admin:
      client:
        url: http://localhost:8080
        instance:
          name: ${spring.application.name}
          metadata:
            tags:
              environment: ${spring.profiles.active}
  application:
    name: otter
  datasource:
    url: jdbc:postgresql://localhost:5432/otter
    username: postgres
    password: postgres
    driver-class-name: org.postgresql.Driver
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
  redis:
    host: localhost
    port: 6379
    database: 0
    timeout: 10000
    lettuce:
      pool:
        max-active: 8
        max-wait: -1
        max-idle: 8
        min-idle: 0
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus,metrics
  endpoint:
    health:
      show-details: always
    prometheus:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
    distribution:
      percentiles-histogram:
        http.server.requests: true
      sla:
        http.server.requests: 10ms, 50ms, 100ms, 200ms, 500ms
logging:
  level:
    root: INFO
    top.heyqing.otter: DEBUG
  file:
    name: logs/application.log
  logback:
    rollingpolicy:
      max-file-size: 10MB
      max-history: 30
app:
  jwt:
    secret: ${JWT_SECRET:your-secret-key-here-must-be-at-least-32-characters}
    expiration: ${JWT_EXPIRATION:86400000} # 24 hours in milliseconds

ipfs:
  api:
    host: ${IPFS_API_HOST:localhost}
    port: ${IPFS_API_PORT:5001}

web3:
  provider:
    url: ${WEB3_PROVIDER_URL:http://localhost:8545}

openai:
  api:
    key: ${OPENAI_API_KEY:your-api-key-here}
    model: ${OPENAI_MODEL:gpt-3.5-turbo}
    temperature: ${OPENAI_TEMPERATURE:0.7}
    max-tokens: ${OPENAI_MAX_TOKENS:2000}